{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOqL-ERxwMDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "2dd69db1-6c9d-4bd8-f044-393656c00a70"
      },
      "source": [
        "# GPU 정보 \n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun 23 00:34:09 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUbPw_7Bf9Jr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "fe8dc0dc-32ee-4cc1-90e2-6f521707e629"
      },
      "source": [
        "# 현재 CUDA 10.1이라 mxnet-cu101로 설치\n",
        "# CUDA에 맞는 mxnet 버전을 선택해야함 (https://mxnet.apache.org/get_started 참조)\n",
        "# 만약 GPU 사용을 하고 있지 않다는 문구가 뜬다면 올바른 버전이 아님\n",
        "!pip install mxnet-cu101"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mxnet-cu101 in /usr/local/lib/python3.6/dist-packages (1.6.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101) (0.8.4)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101) (1.18.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2020.4.5.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WKGlGahhDAL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "ef5b51f2-bff8-4090-cfa1-f0228124fb60"
      },
      "source": [
        "# 패키지 설치\n",
        "!pip install gluonnlp sentencepiece pandas"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gluonnlp in /usr/local/lib/python3.6/dist-packages (0.9.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.91)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (0.29.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (20.4)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc9gWX3SkP6G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a4236e2-4bb2-4328-92e7-404ce622f02b"
      },
      "source": [
        "!pip install git+https://github.com/SKT-AI/KoGPT2#egg=kogpt2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kogpt2 from git+https://github.com/SKT-AI/KoGPT2#egg=kogpt2 in /usr/local/lib/python3.6/dist-packages (0.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8W3gZk2ijYN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "0b29cd05-704c-4bfd-932c-61bd506ea96f"
      },
      "source": [
        "# KoGPT2-chatbot 복사\n",
        "!git clone --recurse-submodules https://github.com/haven-jeon/KoGPT2-chatbot.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'KoGPT2-chatbot'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects:   3% (1/33)\u001b[K\rremote: Counting objects:   6% (2/33)\u001b[K\rremote: Counting objects:   9% (3/33)\u001b[K\rremote: Counting objects:  12% (4/33)\u001b[K\rremote: Counting objects:  15% (5/33)\u001b[K\rremote: Counting objects:  18% (6/33)\u001b[K\rremote: Counting objects:  21% (7/33)\u001b[K\rremote: Counting objects:  24% (8/33)\u001b[K\rremote: Counting objects:  27% (9/33)\u001b[K\rremote: Counting objects:  30% (10/33)\u001b[K\rremote: Counting objects:  33% (11/33)\u001b[K\rremote: Counting objects:  36% (12/33)\u001b[K\rremote: Counting objects:  39% (13/33)\u001b[K\rremote: Counting objects:  42% (14/33)\u001b[K\rremote: Counting objects:  45% (15/33)\u001b[K\rremote: Counting objects:  48% (16/33)\u001b[K\rremote: Counting objects:  51% (17/33)\u001b[K\rremote: Counting objects:  54% (18/33)\u001b[K\rremote: Counting objects:  57% (19/33)\u001b[K\rremote: Counting objects:  60% (20/33)\u001b[K\rremote: Counting objects:  63% (21/33)\u001b[K\rremote: Counting objects:  66% (22/33)\u001b[K\rremote: Counting objects:  69% (23/33)\u001b[K\rremote: Counting objects:  72% (24/33)\u001b[K\rremote: Counting objects:  75% (25/33)\u001b[K\rremote: Counting objects:  78% (26/33)\u001b[K\rremote: Counting objects:  81% (27/33)\u001b[K\rremote: Counting objects:  84% (28/33)\u001b[K\rremote: Counting objects:  87% (29/33)\u001b[K\rremote: Counting objects:  90% (30/33)\u001b[K\rremote: Counting objects:  93% (31/33)\u001b[K\rremote: Counting objects:  96% (32/33)\u001b[K\rremote: Counting objects: 100% (33/33)\u001b[K\rremote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects:   4% (1/24)\u001b[K\rremote: Compressing objects:   8% (2/24)\u001b[K\rremote: Compressing objects:  12% (3/24)\u001b[K\rremote: Compressing objects:  16% (4/24)\u001b[K\rremote: Compressing objects:  20% (5/24)\u001b[K\rremote: Compressing objects:  25% (6/24)\u001b[K\rremote: Compressing objects:  29% (7/24)\u001b[K\rremote: Compressing objects:  33% (8/24)\u001b[K\rremote: Compressing objects:  37% (9/24)\u001b[K\rremote: Compressing objects:  41% (10/24)\u001b[K\rremote: Compressing objects:  45% (11/24)\u001b[K\rremote: Compressing objects:  50% (12/24)\u001b[K\rremote: Compressing objects:  54% (13/24)\u001b[K\rremote: Compressing objects:  58% (14/24)\u001b[K\rremote: Compressing objects:  62% (15/24)\u001b[K\rremote: Compressing objects:  66% (16/24)\u001b[K\rremote: Compressing objects:  70% (17/24)\u001b[K\rremote: Compressing objects:  75% (18/24)\u001b[K\rremote: Compressing objects:  79% (19/24)\u001b[K\rremote: Compressing objects:  83% (20/24)\u001b[K\rremote: Compressing objects:  87% (21/24)\u001b[K\rremote: Compressing objects:  91% (22/24)\u001b[K\rremote: Compressing objects:  95% (23/24)\u001b[K\rremote: Compressing objects: 100% (24/24)\u001b[K\rremote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "Unpacking objects:   3% (1/33)   \rUnpacking objects:   6% (2/33)   \rUnpacking objects:   9% (3/33)   \rUnpacking objects:  12% (4/33)   \rUnpacking objects:  15% (5/33)   \rUnpacking objects:  18% (6/33)   \rUnpacking objects:  21% (7/33)   \rUnpacking objects:  24% (8/33)   \rUnpacking objects:  27% (9/33)   \rUnpacking objects:  30% (10/33)   \rUnpacking objects:  33% (11/33)   \rUnpacking objects:  36% (12/33)   \rUnpacking objects:  39% (13/33)   \rUnpacking objects:  42% (14/33)   \rUnpacking objects:  45% (15/33)   \rremote: Total 33 (delta 11), reused 21 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects:  48% (16/33)   \rUnpacking objects:  51% (17/33)   \rUnpacking objects:  54% (18/33)   \rUnpacking objects:  57% (19/33)   \rUnpacking objects:  60% (20/33)   \rUnpacking objects:  63% (21/33)   \rUnpacking objects:  66% (22/33)   \rUnpacking objects:  69% (23/33)   \rUnpacking objects:  72% (24/33)   \rUnpacking objects:  75% (25/33)   \rUnpacking objects:  78% (26/33)   \rUnpacking objects:  81% (27/33)   \rUnpacking objects:  84% (28/33)   \rUnpacking objects:  87% (29/33)   \rUnpacking objects:  90% (30/33)   \rUnpacking objects:  93% (31/33)   \rUnpacking objects:  96% (32/33)   \rUnpacking objects: 100% (33/33)   \rUnpacking objects: 100% (33/33), done.\n",
            "Submodule 'Chatbot_data' (https://github.com/haven-jeon/Chatbot_data.git) registered for path 'Chatbot_data'\n",
            "Cloning into '/content/KoGPT2-chatbot/Chatbot_data'...\n",
            "remote: Enumerating objects: 20, done.        \n",
            "remote: Total 20 (delta 0), reused 0 (delta 0), pack-reused 20        \n",
            "Submodule path 'Chatbot_data': checked out '235fac5aea3badab22743f7048afe936cf72f822'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9ZweKmXiuaK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57d2b3f3-ac0f-45d7-f4da-c95d1a5ff21e"
      },
      "source": [
        "# 폴더 이동\n",
        "%cd KoGPT2-chatbot"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/KoGPT2-chatbot\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKMZv-ZsiqkB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "outputId": "c9ef9c22-f4e8-43e4-99ae-069509724e5a"
      },
      "source": [
        "# 사전훈련된 KoGPT2를 챗봇 데이터로 파인튜닝\n",
        "!CUDA_VISIBLE_DEVICES=0 python train.py --num-epoch 2 --train"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[██████████████████████████████████████████████████]\n",
            "[██████████████████████████████████████████████████]\n",
            "using cached model\n",
            "INFO:root:contexts : 오늘이 생일이네\n",
            "INFO:root:toked ctx: ['<usr>', '▁오늘', '이', '▁생', '일이', '네', '</s>', '<unused1>', '▁1', '</s>']\n",
            "INFO:root:response : 기억에서 지울 순 없지만 최대한 생각 말아보셔요.\n",
            "INFO:root:toked response : ['<sys>', '▁기억', '에서', '▁지', '울', '▁순', '▁없지만', '▁최대한', '▁생각', '▁말아', '보', '셔', '요', '.', '</s>']\n",
            "INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁기억', '에서', '▁지', '울', '▁순', '▁없지만', '▁최대한', '▁생각', '▁말아', '보', '셔', '요', '.', '</s>']\n",
            "INFO:root:contexts : 재회를 위한 기다림\n",
            "INFO:root:toked ctx: ['<usr>', '▁재', '회를', '▁위한', '▁기다', '림', '</s>', '<unused1>', '▁1', '</s>']\n",
            "INFO:root:response : 가만히 있는다고 달라지는 건 없을 거예요.\n",
            "INFO:root:toked response : ['<sys>', '▁가만히', '▁있는', '다고', '▁달라지는', '▁건', '▁없을', '▁거예요', '.', '</s>']\n",
            "INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁가만히', '▁있는', '다고', '▁달라지는', '▁건', '▁없을', '▁거예요', '.', '</s>']\n",
            "INFO:root:contexts : 8년 사귀고 헤어진지 2달\n",
            "INFO:root:toked ctx: ['<usr>', '▁8', '년', '▁사귀', '고', '▁헤어진', '지', '▁2', '달', '</s>', '<unused1>', '▁1', '</s>']\n",
            "INFO:root:response : 딱 힘들 때네요.\n",
            "INFO:root:toked response : ['<sys>', '▁딱', '▁힘들', '▁때', '네요', '.', '</s>']\n",
            "INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁딱', '▁힘들', '▁때', '네요', '.', '</s>']\n",
            "INFO:root:contexts : 핸드폰게임 자꾸 하게돼\n",
            "INFO:root:toked ctx: ['<usr>', '▁핸드폰', '게임', '▁자꾸', '▁하게', '돼', '</s>', '<unused1>', '▁0', '</s>']\n",
            "INFO:root:response : 시간을 정해보세요.\n",
            "INFO:root:toked response : ['<sys>', '▁시간을', '▁정해', '보세요', '.', '</s>']\n",
            "INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁시간을', '▁정해', '보세요', '.', '</s>']\n",
            "INFO:root:contexts : 관계가 계속 애매하다.\n",
            "INFO:root:toked ctx: ['<usr>', '▁관계가', '▁계속', '▁애매', '하다', '.', '</s>', '<unused1>', '▁0', '</s>']\n",
            "INFO:root:response : 인간 관계도 정리가 필요해요.\n",
            "INFO:root:toked response : ['<sys>', '▁인간', '▁관계', '도', '▁정', '리가', '▁필요', '해요', '.', '</s>']\n",
            "INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁인간', '▁관계', '도', '▁정', '리가', '▁필요', '해요', '.', '</s>']\n",
            "[Epoch 1 Batch 50/185] loss=1.0495, lr=0.0000480480, train ppl=2.856\n",
            "[Epoch 1 Batch 100/185] loss=0.9733, lr=0.0000405405, train ppl=2.647\n",
            "[Epoch 1 Batch 150/185] loss=0.9670, lr=0.0000330330, train ppl=2.630\n",
            "[Epoch 2 Batch 15/185] loss=0.2846, lr=0.0000255255, train ppl=1.329\n",
            "[Epoch 2 Batch 65/185] loss=0.9485, lr=0.0000180180, train ppl=2.582\n",
            "[Epoch 2 Batch 115/185] loss=0.9515, lr=0.0000105105, train ppl=2.589\n",
            "[Epoch 2 Batch 165/185] loss=0.9573, lr=0.0000030030, train ppl=2.605\n",
            "INFO:root:saving model file to kogpt2_chat.params\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3yDcidi6wFA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "3295c36b-16c1-42e6-9333-2bc21058f4d7"
      },
      "source": [
        "# 대화 테스트, `quit`를 입력하면 대화를 종료합니다.\n",
        "!CUDA_VISIBLE_DEVICES=0 python train.py --chat"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cached model\n",
            "using cached model\n",
            "using cached model\n",
            "user > 어버이날에는 뭐 하지?\n",
            "Simsimi > 부모님께 효도하는거요.\n",
            "user > 아 더워 미치겠음..\n",
            "Simsimi > 시원한 물 한 잔 드세요.\n",
            "user > quit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoeGog7OoXFk",
        "colab_type": "text"
      },
      "source": [
        "이 노트북은   https://colab.research.google.com/drive/1Np7d8zrch589LwwW9oX_MyzJ9jfPEvUG?usp=sharing  를 수정하여 만들었습니다..  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "KoGPT2_chatbot.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}